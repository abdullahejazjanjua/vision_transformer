# Vision Transformer (ViT) Implementation

A PyTorch implementation of Vision Transformer (ViT) from scratch. This repository contains a clean, educational implementation of the attention mechanism and transformer architecture for computer vision tasks.

## Features

- Custom multi-head attention implementation
- Efficient attention computation with 3x speedup
- Educational code with clear variable names and comments
- Modular design for easy understanding
